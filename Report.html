<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Benjamin Mohn" />

<meta name="date" content="2018-10-29" />

<title>Practcal Machine Learning</title>

<script src="Report_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Report_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Report_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Report_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Report_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="Report_files/navigation-1.1/tabsets.js"></script>
<link href="Report_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Report_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Practcal Machine Learning</h1>
<h4 class="author"><em>Benjamin Mohn</em></h4>
<h4 class="date"><em>10/29/2018</em></h4>

</div>


<div id="predict-quantity-of-barbell-lifts" class="section level2">
<h2>Predict Quantity of barbell lifts</h2>
<p>In the following report I am going to predict the quantity in which one out six participants performed one set of 10 barbell lifts. Each of the participants was asked to perform the lift in 5 different ways and was wearing accelerometer on the belt, forearm and arm and as well the dumbbell got an accelerometer. The data I am going to use is from this source: <a href="http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har" class="uri">http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har</a> The dataset is licensed under the Creative Commons license (CC BY-SA) The data is directly splitted into to test and training set and the variable I am going to predict os the <strong>classe</strong> variable. The classes are as followns:</p>
<ul>
<li>A := exactly according to specification</li>
<li>B := throwing the elbows to the front</li>
<li>C := lifting the dumbbell halfway</li>
<li>D := lowering the dumbbell halfway</li>
<li>E := throwing hips to the front</li>
</ul>
<p>The original data and first publication is the following one, which I am citing for completness reasons: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.</p>
</div>
<div id="loading-data" class="section level2">
<h2>Loading data</h2>
<pre class="r"><code>download.file(&#39;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&#39;, &#39;train_set.csv&#39;, quiet=TRUE)
download.file(&#39;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&#39;, &#39;test_set.csv&#39;, quiet=TRUE)
training &lt;- read.csv(&#39;train_set.csv&#39;)
testing &lt;- read.csv(&#39;test_set.csv&#39;)</code></pre>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<pre class="r"><code>dim(training)</code></pre>
<pre><code>## [1] 19622   160</code></pre>
<pre class="r"><code>dim(testing)</code></pre>
<pre><code>## [1]  20 160</code></pre>
<p>There are 160 Variables and 19622 observation in the training set and 20 observation in the test set.</p>
<pre class="r"><code>names(training)[1:10]</code></pre>
<pre><code>##  [1] &quot;X&quot;                    &quot;user_name&quot;            &quot;raw_timestamp_part_1&quot;
##  [4] &quot;raw_timestamp_part_2&quot; &quot;cvtd_timestamp&quot;       &quot;new_window&quot;          
##  [7] &quot;num_window&quot;           &quot;roll_belt&quot;            &quot;pitch_belt&quot;          
## [10] &quot;yaw_belt&quot;</code></pre>
<p>The first seven columns describe the observation, so there are things like, the name, the set and timestamps. I do not assume those values to have an influence on the <em>classe</em> variable. Therefore I will remove them in a later step. After the first 7 features there are several measurements for each of the 4 accelerometers.</p>
<pre class="r"><code>unique(sapply(training[sapply(training,  function(x) sum(is.na(x))) &gt; 0 ], function(c) sum(is.na(c))))</code></pre>
<pre><code>## [1] 19216</code></pre>
<p>What is interesting is, that it seems that there is either no Na’s or 19216 so there seems to be some pattern. Unfortunatly in the documentation I could not find any hint what could be the reason for this. Therefore I will exclude this paramters and see if I am able to get a reasonably good model without them.</p>
<pre class="r"><code>reduced_training &lt;- training[sapply(training,  function(x) sum(is.na(x))) == 0 ]</code></pre>
<p>Next thing I want to do is to exclude the first 7 columns.</p>
<pre class="r"><code>further_reduced_training &lt;- reduced_training[, - (1:7)]</code></pre>
<p>My idea is to use Cross Validation on all numeric parameters. Therefore I am now filtering for those.</p>
<pre class="r"><code>final_training &lt;- further_reduced_training[sapply(further_reduced_training, is.numeric)]
final_training$classe &lt;- further_reduced_training$classe</code></pre>
<p>Now I am going to do several boxplots to get some feeling for the data. I am going to plot the combined statistics for each accelerator aggainst the classes.</p>
<p><img src="Report_files/figure-html/plot_arm-1.png" width="672" /></p>
<p><img src="Report_files/figure-html/plot_forearm-1.png" width="672" /> <img src="Report_files/figure-html/plot_belt-1.png" width="672" /> <img src="Report_files/figure-html/plot_dumbbell-1.png" width="672" /></p>
</div>
<div id="model-fitting" class="section level2">
<h2>Model fitting</h2>
<p>In all these graphics there is not really a huge different beetween the variables visible. Therefore I am going to try now a crossvalidation on the complete data set with different models of the caret package. I will use k-Fold cross validation with k set to 3 becaue of timing issues. Therefore I will assign a new variable <em>fold</em> to the data which holds the information in which group a observation falls.</p>
<pre class="r"><code>require(caret)</code></pre>
<pre><code>## Loading required package: caret</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre class="r"><code>set.seed(29102018)
final_training$fold &lt;- createFolds(final_training$classe, k=3, list=FALSE)</code></pre>
<p>Now I can fit models holding one of the groups out. Since the code is allways the same, I will just show it for one model. The seet will be always the same.</p>
<div id="tree---models" class="section level3">
<h3>Tree - Models</h3>
<pre class="r"><code>set.seed(29102018)
tree1 &lt;- train(classe~., data= final_training[(final_training$fold != 1),-54], method=&quot;rpart&quot;)</code></pre>
</div>
<div id="generalized-boosting-models" class="section level3">
<h3>Generalized Boosting Models</h3>
<pre class="r"><code>set.seed(29102018)
gbm1 &lt;- train(classe~., data= final_training[(final_training$fold != 1),-54], method=&quot;gbm&quot;, verbose=FALSE)</code></pre>
</div>
<div id="linear-discriminant-analysis" class="section level3">
<h3>Linear discriminant Analysis</h3>
<pre class="r"><code>set.seed(29102018)
lda1 &lt;- train(classe~., data= final_training[(final_training$fold != 1),-54], method=&quot;lda&quot;)</code></pre>
</div>
</div>
<div id="evaluation" class="section level2">
<h2>Evaluation</h2>
<p>Now that I have fitted the different models I am going to evaluate them. This I will do be using a Confusion Matrix for each of them and then taking the average of the accurcies. That model which reached the highest accuraccy I will fit once more on the entire data set and then use to do a prediction on the testing set. I will show the code for one example the rest will be similar.</p>
<pre class="r"><code>predictTree1 &lt;- predict(tree1,  final_training[(final_training$fold == 1),-54])

confusionTree1 &lt;- confusionMatrix(data = predictTree1, reference = final_training[(final_training$fold == 1),]$classe)</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<pre class="r"><code>mean(c(confusionTree1$overall[1],confusionTree2$overall[1],confusionTree3$overall[1]))</code></pre>
<pre><code>## [1] 0.4950052</code></pre>
<pre class="r"><code>mean(c(confusionGBM1$overall[1],confusionGBM2$overall[1],confusionGBM3$overall[1]))</code></pre>
<pre><code>## [1] 0.9604526</code></pre>
<pre class="r"><code>mean(c(confusionLDA1$overall[1],confusionLDA2$overall[1],confusionLDA3$overall[1]))</code></pre>
<pre><code>## [1] 0.699674</code></pre>
<p>The results show, that the normal tree algorithm performed worse amoung the three testes models. Everage accuracy is less then 50%. The genarilzed boosting models where by far the best with an average accuraccy of 96%. Therefore I will learn the final model as an <em>GBM</em>. So I can expect an accurracy of 96% and an out of sample error of 4%.</p>
<pre class="r"><code>best_model &lt;-  train(classe~., data= final_training[,-54], method=&quot;gbm&quot;, verbose=FALSE)</code></pre>
</div>
<div id="predicting" class="section level2">
<h2>Predicting</h2>
<p>Now I am going to predict the outomes for the testing set. First thing I need to do is to bring the data in the same format. In this case it means, that I have to drop the columns I also dropped in the training set.</p>
<pre class="r"><code>final_testing &lt;- testing[,names(final_training[,-c(53,54)])]</code></pre>
<p>The predictions according to the model I have trained are:</p>
<pre class="r"><code>predict(best_model, final_testing)</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
